## Определение токсичности комментариев

**Задача:** построить модель, которая будет отсеивать токсичные комментарии на основании набора данных с разметкой о токсичности правок. </br>
**Условие:** метрика качества F1 не меньше 0.75.</br>

### Выводы:

- При подготовке данных из датасета был выделен корпус из 50.000 текстов для обучения и 12.500 текстов для проверки моделей.
- Тексты были лемматизированы, очищены от цифр, символов и стоп-стов.
- Для векторизации текста применялись CountVectorizer, TF-IDF и Word2vec
- Для задачи классификации были использованы логистическая регрессия, градиентный бустинг, метод опорных векторов и дерево решений
- Все модели прошли проверку на адекватность в сравнении со случайной моделью
- По итогам скоринговой таблицы лучшими оказались логистическая регрессия в применении к мешку слов с биграммами, градиентный бустинг в применении к мешку слов и метод опорных векторов для TF-IDF.
- Была определена функция для простроения голосующего ансамбля из трех лучших моделей

Была создана модель классификации комментариев по уровню токсичности, опробованы различные методы векторизации и различные модели машинного обучения с учителем. На основе трех наиболее успешных моделей был создан ансамбль, который позволил добиться метрики f1 на тестовых данных = 0.77
